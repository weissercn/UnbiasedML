{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from models import Classifier, WeightedMSE, FlatLoss\n",
    "from utils import Metrics, find_threshold, DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.load(\"data/W_FCN_v0.npz\")\n",
    "train = files[\"train\"]\n",
    "val = files[\"val\"]\n",
    "\n",
    "maxdata = train.max(axis=0)\n",
    "mindata = train.min(axis=0)\n",
    "train = (train-mindata)/(maxdata-mindata)\n",
    "maxdata = val.max(axis=0)\n",
    "mindata = val.min(axis=0)\n",
    "val = (val-mindata)/(maxdata-mindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = DataSet(samples=train[::,1:-1].astype(float),\n",
    "                       labels=train[::,-1].astype(int),\n",
    "                       m = train[::,0].astype(float))\n",
    "valdataset = DataSet(samples=val[:,1:-1].astype(float),\n",
    "                     labels=val[:,-1].astype(int),\n",
    "                    m = val[:,0].astype(float))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac=0.93\n",
    "print(\"strength\",frac/(1-frac))\n",
    "params = {'epochs'     : 400,\n",
    "          'interval'   : 100,\n",
    "          'batch_size' : 2048,\n",
    "          'shuffle'    : True,\n",
    "          'num_workers': 6,\n",
    "          'drop_last'  :True,\n",
    "          'device'     : device,\n",
    "          'pass_x_biased':True,\n",
    "         }\n",
    "\n",
    "metrics_train_L = Metrics()\n",
    "metrics_val_L = Metrics(validation=True)\n",
    "torch.manual_seed(69)\n",
    "model_L = Classifier().to(device)\n",
    "optimizer = torch.optim.SGD(model_L.parameters(),lr=1e-1,momentum=0.)\n",
    "loss =  FlatLoss(labels=traindataset.labels,frac=frac)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=200, gamma=0.9)\n",
    "model_L.fit(traindataset=traindataset,\n",
    "            valdataset=valdataset,\n",
    "            loss=loss,\n",
    "            **params,\n",
    "          #scheduler=scheduler,\n",
    "          metrics=[metrics_train_L,metrics_val_L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'epochs' : 400,\n",
    "          'interval'   : 100,\n",
    "          'batch_size' : 1024,\n",
    "          'shuffle'    : True,\n",
    "          'num_workers': 6,\n",
    "          'pass_x_biased':False\n",
    "         }\n",
    "metrics_train = Metrics()\n",
    "metrics_val = Metrics(validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "model = Classifier()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-1,momentum=0.)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=200, gamma=0.9)\n",
    "criterion = WeightedMSE(labels=traindataset.labels)\n",
    "model.fit(traindataset=traindataset,\n",
    "          valdataset=valdataset,\n",
    "          **params,\n",
    "          optimizer= optimizer,\n",
    "          loss=criterion,\n",
    "          #scheduler=scheduler,\n",
    "          metrics=[metrics_train,metrics_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = files[\"test\"]\n",
    "metrics_test = Metrics(validation=True)\n",
    "maxdata = test.max(axis=0)\n",
    "mindata = test.min(axis=0)\n",
    "test = (test-mindata)/(maxdata-mindata)\n",
    "\n",
    "fig, axes = plt.subplots(3,4,figsize=(12,10))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    ax.hist(test[:,i][test[:,-1]==0],bins=25,alpha=0.3)\n",
    "    ax.hist(test[:,i][test[:,-1]==1],bins=25,alpha=0.3)\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(model(torch.Tensor(test[:,1:11]).float()).tolist()).flatten()\n",
    "metrics_test.calculate(pred=predictions, target=test[:,-1])\n",
    "c = find_threshold(predictions,(test[:,-1]==0),0.5)\n",
    "R50 = 1/((predictions[test[:,-1]==1]<c).sum()/(test[:,-1]==1).sum())\n",
    "m =test[:,0]\n",
    "p, bins = np.histogram(m[test[:,-1]==1],bins=50,density = True)\n",
    "q, _ = np.histogram(m[(test[:,-1]==1)&(predictions<c)],bins=bins,density = True)\n",
    "goodidx = (p!=0)&(q!=0)\n",
    "p = p[goodidx]\n",
    "q = q[goodidx]\n",
    "JSD = np.sum(.5*(p*np.log2(p)+q*np.log2(q)-(p+q)*np.log2((p+q)*0.5)))*(bins[1]-bins[0])\n",
    "print(R50.item())\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,4),dpi=150)\n",
    "_,bins,_ = ax.hist(test[:,0][(test[:,-1]==1)],bins=50,alpha=0.3,color='C1',label='Background',density=True)\n",
    "ax.hist(test[:,0][(test[:,-1]==1)&(predictions<c)],bins=bins,alpha=0.3,color='C0',label='False Positives',density=True)\n",
    "ax.set_ylabel(\"Normed Counts\",fontsize=20)\n",
    "ax.set_xlabel(r\"$m$\",fontsize=20)\n",
    "plt.title('Naive DNN (R50:{:.2f}, 1/JSD:{:.2f})'.format(R50,1/JSD))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiencies = np.linspace(0.1,0.9,9)\n",
    "cuts = []\n",
    "for eff in efficiencies:\n",
    "    cuts.append(find_threshold(predictions,(test[:,-1]==0),eff))\n",
    "\n",
    "\n",
    "m_t = test[:,0]\n",
    "sorted_m = np.argsort(m_t)\n",
    "\n",
    "scores = predictions[sorted_m].reshape(-1,100)\n",
    "\n",
    "m_t = m_t[sorted_m]\n",
    "m = m_t.reshape(-1,100).mean(axis=1)\n",
    "F_s = []\n",
    "for s in scores.reshape(50,-1):\n",
    "    density = np.histogram(s,bins=50,range=(0,1))[0]\n",
    "    F_s.append(np.cumsum(density)/density.sum())\n",
    "F_s = np.array(F_s).T\n",
    "fig, ax1 = plt.subplots(1,1,figsize=(5,4),dpi=150)\n",
    "for j,cut in enumerate(cuts):\n",
    "    c = f\"C{j}\" #if j!= 6 else f\"C11\"\n",
    "    passed = (scores<cut).sum(axis=1)/scores.shape[1]\n",
    "    ax1.plot(m,passed,label=\"{:0.1f} ({:0.2f})\".format(efficiencies[j],cut),alpha=0.9,c=c,lw=1)\n",
    "\n",
    "ax1.set_ylabel(r\"$\\mathrm{passing\\, events}/\\mathrm{events\\,in\\, bin}$\",fontsize=17)\n",
    "ax1.set_ylim([-0.02,1.02])\n",
    "#ax1.set_title(\"(strength: {:.02f}, acc: {:.02})\".format(1, metrics_val_legendre.accs[-1]),fontsize=17)\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1,1) ,markerscale=5,title=\"SE (Cut)\",ncol=1)\n",
    "ax1.set_xlabel(r\"$m$\",fontsize=19)\n",
    "\n",
    "fig.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(model_L(torch.Tensor(test[:,1:11]).float()).tolist()).flatten()\n",
    "metrics_test.calculate(pred=predictions, target=test[:,-1])\n",
    "c = find_threshold(predictions,(test[:,-1]==0),0.5)\n",
    "R50 = 1/((predictions[test[:,-1]==1]<c).sum()/(test[:,-1]==1).sum())\n",
    "m =test[:,0]\n",
    "p, bins = np.histogram(m[test[:,-1]==1],bins=50,density = True)\n",
    "q, _ = np.histogram(m[(test[:,-1]==1)&(predictions<c)],bins=bins,density = True)\n",
    "goodidx = (p!=0)&(q!=0)\n",
    "p = p[goodidx]\n",
    "q = q[goodidx]\n",
    "JSD = np.sum(.5*(p*np.log2(p)+q*np.log2(q)-(p+q)*np.log2((p+q)*0.5)))*(bins[1]-bins[0])\n",
    "print(R50.item())\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,4),dpi=150)\n",
    "_,bins,_ = ax.hist(test[:,0][(test[:,-1]==1)],bins=50,alpha=0.3,color='C1',label='Background',density=True)\n",
    "ax.hist(test[:,0][(test[:,-1]==1)&(predictions<c)],bins=bins,alpha=0.3,color='C0',label='False Positives',density=True)\n",
    "ax.set_ylabel(\"Normed Counts\",fontsize=20)\n",
    "ax.set_xlabel(r\"$m$\",fontsize=20)\n",
    "plt.title('FlatLoss DNN (R50:{:.2f}, 1/JSD:{:.2f})'.format(R50,1/JSD))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "efficiencies = np.linspace(0.1,0.9,9)\n",
    "cuts = []\n",
    "for eff in efficiencies:\n",
    "    cuts.append(find_threshold(predictions,(test[:,-1]==0),eff))\n",
    "\n",
    "\n",
    "m_t = test[:,0]\n",
    "sorted_m = np.argsort(m_t)\n",
    "\n",
    "scores = predictions[sorted_m].reshape(-1,100)\n",
    "\n",
    "m_t = m_t[sorted_m]\n",
    "m = m_t.reshape(-1,100).mean(axis=1)\n",
    "F_s = []\n",
    "for s in scores.reshape(50,-1):\n",
    "    density = np.histogram(s,bins=50,range=(0,1))[0]\n",
    "    F_s.append(np.cumsum(density)/density.sum())\n",
    "F_s = np.array(F_s).T\n",
    "fig, ax1 = plt.subplots(1,1,figsize=(5,4),dpi=150)\n",
    "for j,cut in enumerate(cuts):\n",
    "    c = f\"C{j}\" #if j!= 6 else f\"C11\"\n",
    "    passed = (scores<cut).sum(axis=1)/scores.shape[1]\n",
    "    ax1.plot(m,passed,label=\"{:0.1f} ({:0.2f})\".format(efficiencies[j],cut),alpha=0.9,c=c,lw=1)\n",
    "\n",
    "ax1.set_ylabel(r\"$\\mathrm{passing\\, events}/\\mathrm{events\\,in\\, bin}$\",fontsize=17)\n",
    "ax1.set_ylim([-0.02,1.02])\n",
    "#ax1.set_title(\"(strength: {:.02f}, acc: {:.02})\".format(1, metrics_val_legendre.accs[-1]),fontsize=17)\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1,1) ,markerscale=5,title=\"SE (Cut)\",ncol=1)\n",
    "ax1.set_xlabel(r\"$m$\",fontsize=19)\n",
    "\n",
    "fig.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
