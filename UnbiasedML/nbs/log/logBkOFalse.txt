********************************************************************************
Model initialized on: 11/03/2020 11:54:39
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.00/0.00, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (33.6 s)
 Train: loss:0.1618, acc:77% || Val: loss: 0.1624, acc:78%, R50: 11.2087, 1/JSD: 3.7598
Epoch:0200/0200  (69.4 s)
 Train: loss:0.1607, acc:79% || Val: loss: 0.1599, acc:78%, R50: 11.4777, 1/JSD: 3.9537

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 11:55:50
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.33/0.22, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (42.3 s)
 Train: loss:0.1086, acc:78% || Val: loss: 0.1672, acc:77%, R50: 11.0728, 1/JSD: 4.1540
Epoch:0200/0200  (82.5 s)
 Train: loss:0.1081, acc:78% || Val: loss: 0.1611, acc:78%, R50: 11.1837, 1/JSD: 3.8322

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 11:57:14
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.50/0.25, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (38.6 s)
 Train: loss:0.0849, acc:78% || Val: loss: 0.1709, acc:77%, R50: 10.8105, 1/JSD: 4.3049
Epoch:0200/0200  (77.4 s)
 Train: loss:0.0833, acc:77% || Val: loss: 0.1624, acc:78%, R50: 11.1837, 1/JSD: 3.8786

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 11:58:33
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.67/0.22, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (46.2 s)
 Train: loss:0.0682, acc:70% || Val: loss: 0.2050, acc:69%, R50: 5.5733, 1/JSD: 11.9917
Epoch:0200/0200  (84.4 s)
 Train: loss:0.0581, acc:78% || Val: loss: 0.1724, acc:77%, R50: 10.6727, 1/JSD: 4.8180

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 11:59:59
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.75/0.19, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (38.9 s)
 Train: loss:0.0515, acc:70% || Val: loss: 0.2073, acc:68%, R50: 5.3995, 1/JSD: 11.8911
Epoch:0200/0200  (77.8 s)
 Train: loss:0.0442, acc:76% || Val: loss: 0.1762, acc:76%, R50: 10.0230, 1/JSD: 5.2106

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 12:01:18
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.83/0.14, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (42.0 s)
 Train: loss:0.0362, acc:68% || Val: loss: 0.2174, acc:66%, R50: 4.4497, 1/JSD: 6.6555
Epoch:0200/0200  (81.9 s)
 Train: loss:0.0334, acc:72% || Val: loss: 0.1971, acc:72%, R50: 6.6247, 1/JSD: 9.7735

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 12:02:41
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.91/0.08, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (46.7 s)
 Train: loss:0.0208, acc:66% || Val: loss: 0.2259, acc:65%, R50: 4.0975, 1/JSD: 6.5421
Epoch:0200/0200  (89.3 s)
 Train: loss:0.0194, acc:67% || Val: loss: 0.2101, acc:67%, R50: 4.9866, 1/JSD: 7.1948

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 12:04:12
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.94/0.06, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (39.2 s)
 Train: loss:0.0149, acc:64% || Val: loss: 0.2378, acc:65%, R50: 3.6587, 1/JSD: 5.8861
Epoch:0200/0200  (78.7 s)
 Train: loss:0.0142, acc:65% || Val: loss: 0.2233, acc:65%, R50: 4.1295, 1/JSD: 6.2826

*************************Finished Training Successfully*************************

********************************************************************************
Model initialized on: 11/03/2020 12:05:32
   epochs    batch_size   shuffle   num_workers   interval   drop_last   delay_loss pass_x_biased
    200         4096         1           6          100          0           0           1      

**Loss**
Flat Loss: frac/strength=0.95/0.05, norm=L2, background_only=False, bins=128
Weighted MSE:  c0=1.0   c1=1.002

**Optimizer**
SGD (Parameter Group 0    dampening: 0    lr: 0.1    momentum: 0.0    nesterov: False    weight_decay: 0)

Epoch:0100/0200  (47.2 s)
 Train: loss:0.0117, acc:61% || Val: loss: 0.2455, acc:61%, R50: 3.5005, 1/JSD: 113.5838
Epoch:0200/0200  (87.0 s)
 Train: loss:0.0115, acc:62% || Val: loss: 0.2386, acc:63%, R50: 4.0431, 1/JSD: 17.7208

*************************Finished Training Successfully*************************

